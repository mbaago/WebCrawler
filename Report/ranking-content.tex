\section{Ranking (content-based)}
To rank our result we use term frequency (TF) and the inverse document frequency (IDF).

\subsection{Term Frequency}
This is the number of times a given term is found on a page. To avoid making pages where a term is used a lot much more important than the pages where it is less frequent, the TF is normalized as follows:
\[
    \log_{10}(\text{the number of times the term is found in the document})
\]
The use of $\log$, as opposed to other ways of normalization, is to give pages with a high term count a slightly better score the those with lower.

\subsection{Inverse Document Frequency}
The IDF is calculated as follows
\[
    \frac{ \text{number of pages in the database}}{ \text{the number of pages with the term in them}}
\]
Again to help reduce the impact of terms used on many pages the value use is
\[
    \log_{10}\Big(\frac{ \text{number of pages in the database}}{ \text{the number of pages with the term in them}}\Big)
\]

\subsection{TF*IDF}
The final score for a page is calculated as follows, where $q$ is the query, and $p$ is the page content.
\[
    \sum_{t \in q \cap p}{TF \times IDF_{q,p}}
\]
\subsection{Cosine Similarity}
A further improvement to this approach would be to calculate the cosine similarity. The cosine similarity between a query and a page is done as follows:
\[
    \frac{query \cdot page}{|query| \times |page|}
\]


 